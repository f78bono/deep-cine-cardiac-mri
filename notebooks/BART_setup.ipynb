{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNV++4NsZ3v3DQJXeWImJLX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This notebook shows how to set up a Python environment for the BART library on Google Colab.\n","\n","In this project, BART is used to estimate the coil sensitivity maps via ESPIRiT calibration, in order to generate ground truth coil-combined MRI images from the given dataset of k-space volumes.\n","\n","Running the following code before launching the train_test programs should be enough for things to work smoothly. If errors arise, please refer to the official BART documentation at:\n","- [BART Setup on Colab](https://github.com/mrirecon/bart-workshop/blob/master/ismrm2021/neural_networks/bart_neural_networks.ipynb)\n","- [BART Setup on local machine](https://mrirecon.github.io/bart/)"],"metadata":{"id":"li4Fk7lyuX47"}},{"cell_type":"markdown","metadata":{"id":"17qwMnVqFl9K"},"source":["# Setup BART for Colab"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1mY3soK3C8al","executionInfo":{"status":"ok","timestamp":1667862079062,"user_tz":-60,"elapsed":16,"user":{"displayName":"Francesco Bono","userId":"11189470803682651835"}},"outputId":"8d2900dd-b6b9-48e8-8abb-c62a78e920f8"},"source":["%%bash\n","\n","# Use CUDA 10.1 when on Tesla K80\n","\n","# Estimate GPU Type\n","GPU_NAME=$(nvidia-smi --query-gpu=gpu_name --format=csv,noheader)\n","\n","echo \"GPU Type:\"\n","echo $GPU_NAME\n","\n","if [ \"Tesla K80\" = \"$GPU_NAME\" ];\n","then\n","    echo \"GPU type Tesla K80 does not support CUDA 11. Set CUDA to version 10.1.\"\n","\n","    # Change default CUDA to version 10.1\n","    cd /usr/local\n","    rm cuda\n","    ln -s cuda-10.1 cuda\n","else\n","    echo \"Current GPU supports default CUDA-11.\"\n","    echo \"No further actions are necessary.\"\n","fi\n","\n","echo \"GPU Information:\"\n","nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv\n","nvcc --version"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU Type:\n","Tesla T4\n","Current GPU supports default CUDA-11.\n","No further actions are necessary.\n","GPU Information:\n","name, driver_version, memory.total [MiB]\n","Tesla T4, 460.32.03, 15109 MiB\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2021 NVIDIA Corporation\n","Built on Sun_Feb_14_21:12:58_PST_2021\n","Cuda compilation tools, release 11.2, V11.2.152\n","Build cuda_11.2.r11.2/compiler.29618528_0\n"]}]},{"cell_type":"code","metadata":{"id":"MJrU8MCeDKl3"},"source":["%%bash\n","\n","# Install BARTs dependencies\n","apt-get install -y make gcc libfftw3-dev liblapacke-dev libpng-dev libopenblas-dev &> /dev/null\n","\n","# Clone Bart\n","[ -d /content/bart ] && rm -r /content/bart\n","git clone https://github.com/mrirecon/bart/ bart &> /dev/null"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","\n","cd bart\n","\n","# For long term support, we checkout the following tag:\n","git checkout tags/ISMRM21_NN\n","\n","# Define specifications \n","COMPILE_SPECS=\" PARALLEL=1\n","                CUDA=1\n","                CUDA_BASE=/usr/local/cuda\n","                CUDA_LIB=lib64\n","                OPENBLAS=1\n","                BLAS_THREADSAFE=1\"\n","\n","printf \"%s\\n\" $COMPILE_SPECS > Makefiles/Makefile.local\n","\n","make &> /dev/null"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MD7G5YoENj5w","executionInfo":{"status":"ok","timestamp":1667862149978,"user_tz":-60,"elapsed":56361,"user":{"displayName":"Francesco Bono","userId":"11189470803682651835"}},"outputId":"5f756861-11c9-4c8b-9223-d83659234521"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Note: checking out 'tags/ISMRM21_NN'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by performing another checkout.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -b with the checkout command again. Example:\n","\n","  git checkout -b <new-branch-name>\n","\n","HEAD is now at 5287d1c5 Add tool to transform onehotencoded data to integer encoded\n"]}]},{"cell_type":"code","source":["%env TOOLBOX_PATH=/content/bart"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yv6fkHGdMngD","executionInfo":{"status":"ok","timestamp":1667862149979,"user_tz":-60,"elapsed":14,"user":{"displayName":"Francesco Bono","userId":"11189470803682651835"}},"outputId":"ecb58a80-84f7-4281-f1ce-c04b9f451131"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["env: TOOLBOX_PATH=/content/bart\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","\n","os.environ['PATH'] = os.environ['TOOLBOX_PATH'] + \":\" + os.environ['PATH']\n","sys.path.append(os.environ['TOOLBOX_PATH'] + \"/python/\")"],"metadata":{"id":"tqNbYP6vOJ3t"},"execution_count":null,"outputs":[]}]}